##### SLURM-based pipeline for mapping, filtering, sorting, and deduplicating paired-end RNA/DNA reads using BWA, SAMtools, and Picard. ####


#!/bin/bash -l

#SBATCH--cluster = genius
#SBATCH--job - name chaturvedi_mapping_bam_filtering
#SBATCH--nodes = 1
#SBATCH--ntasks - per - node = 20
#SBATCH--time = 12: 00: 00
#SBATCH - A lp_svbelleghem
#SBATCH - o chaturvedi_map. % j.out
#SBATCH--array = 1 - 24

# This variable will store the job array number minus 1, so we can use it to get a sample from the samples list(index starts at 0)
ID = $((SLURM_ARRAY_TASK_ID - 1))

# Load the programs we will use
module load BWA / 0.7 .17 - foss - 2018 a
module load SAMtools / 1.9 - GCC - 6.4 .0 - 2.28
module load picard / 2.18 .23 - Java - 1.8 .0_171

echo "================="

# Sample IDs(20 samples)
samples = (SRR4340276 SRR4340277 SRR4340297 SRR4340304 SRR4340305 SRR4340306 SRR4340309 SRR4340274 SRR4340275 SRR4340286 SRR4340307 SRR4340308 SRR4340278 SRR4340279 SRR4340280 SRR4340282 SRR4340283 SRR4340284 SRR4340287 SRR4340288 SRR4340289 SRR4340290 SRR4340281 SRR4340285)

echo "${samples[ID]}"

# Some folder and file paths to use later
REF = /lustre1/scratch / 354 / vsc35429 / metastudy_final / FST_CHATURVEDI / maria / genome / ncbi_dataset / data / GCA_030254905 .1 / GCA_030254905 .1_ UOB_LRV0_1_genomic.renamed.fna
REFNAME = magna
BWAout = /lustre1/scratch / 354 / vsc35429 / metastudy_final / FST_CHATURVEDI / maria / bams /
  FILE1 = /lustre1/scratch / 354 / vsc35429 / metastudy_final / FST_CHATURVEDI / $(echo "${samples[ID]}") _1_trimmed.fastq.gz
FILE2 = /lustre1/scratch / 354 / vsc35429 / metastudy_final / FST_CHATURVEDI / $(echo "${samples[ID]}") _2_trimmed.fastq.gz

# Map reads using bwa mem
bwa mem - t 20 - M $REF $FILE1 $FILE2 | samtools view - bS -> $BWAout / $(echo "${samples[ID]}").$REFNAME.bam

# Filter using samtools
samtools view - f 0x02 - q 20 - b\ "${BWAout}/${samples[ID]}.${REFNAME}.bam"\ >
  "${BWAout}/${samples[ID]}.${REFNAME}.filtered.bam"

# Sort using samtools
samtools sort "${BWAout}/${samples[ID]}.${REFNAME}.filtered.bam" - o "${BWAout}/${samples[ID]}.${REFNAME}.filtered.sorted.bam"

# Remove PCR duplicates
java - jar $EBROOTPICARD / picard.jar MarkDuplicates\
INPUT = "${BWAout}/${samples[ID]}.${REFNAME}.filtered.sorted.bam"\
OUTPUT = "${BWAout}/${samples[ID]}.${REFNAME}.filtered.sorted.nd.bam"\
METRICS_FILE = "${BWAout}/${samples[ID]}.${REFNAME}.metrics.txt"\
REMOVE_DUPLICATES = true\
ASSUME_SORTED = true

# Remove intermediate files
#rm $BWAout / $(echo "${samples[ID]}").$REFNAME.bam
#rm $ {
  BWAout
}
/${samples[ID]}.${REFNAME}.filtered.bam
#rm $ {
  BWAout
}
/${samples[ID]}.${REFNAME}.filtered.sorted.bam 

samtools index $ {
  BWAout
}
/${samples[ID]}.${REFNAME}.filtered.sorted.nd.bam
